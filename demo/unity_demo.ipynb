{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Elq1CKh3N5IE"
      },
      "source": [
        "# Demo VirtualHome"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fr8V5spCN5IH"
      },
      "source": [
        "This is a demo of how to run VirtualHome UnitySimulator. The demo will walk though how to start an environment and visualize it, how to prepare it to perform activities and finally how to perform activities in them.\n",
        "\n",
        "<img src=https://raw.githubusercontent.com/xavierpuigf/virtualhome_unity/master/doc/assets/banner.gif />\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RPaEKyXN9Ae"
      },
      "source": [
        "# Setup\n",
        "The code below is only needed if you are running the demo in colab. It installs a package to stream content on Google Colab.\n",
        "\n",
        "**Note:** Make sure you have GPU enabled if you are running in colab. \n",
        "\n",
        "Select Runtime > Change runtime type > Hardware accelerator: GPU\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvYTf6n9N_gO",
        "outputId": "bfb50121-b4b7-4c86-a0a6-fa5829f3dd8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on CoLab\n",
            "Collecting git+https://github.com/xavierpuigf/colabstreamer\n",
            "  Cloning https://github.com/xavierpuigf/colabstreamer to /tmp/pip-req-build-1u5ez241\n",
            "  Running command git clone -q https://github.com/xavierpuigf/colabstreamer /tmp/pip-req-build-1u5ez241\n",
            "Collecting i3ipc\n",
            "  Downloading i3ipc-2.2.1-py3-none-any.whl (26 kB)\n",
            "Collecting python-xlib\n",
            "  Downloading python_xlib-0.31-py2.py3-none-any.whl (179 kB)\n",
            "\u001b[K     |████████████████████████████████| 179 kB 7.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from python-xlib->i3ipc->colabstreamer.py==0.1) (1.15.0)\n",
            "Building wheels for collected packages: colabstreamer.py\n",
            "  Building wheel for colabstreamer.py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for colabstreamer.py: filename=colabstreamer.py-0.1-py3-none-any.whl size=3830 sha256=d51353b360cae9dc9c444326a1c08af4062f5ffb848c2575415dcac7234ab32e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-q8z01s4j/wheels/7e/df/62/68e8e5813ab1ac489ca123bc4051459c61ba909df0ec7ac404\n",
            "Successfully built colabstreamer.py\n",
            "Installing collected packages: python-xlib, i3ipc, colabstreamer.py\n",
            "Successfully installed colabstreamer.py-0.1 i3ipc-2.2.1 python-xlib-0.31\n",
            "Will Install xvfb\n",
            "Will Install xserver-xorg\n",
            "Will Install mesa-utils\n",
            "Will Install xinit\n",
            "Will Install xdotool\n",
            "Will Install linux-generic\n",
            "Will Install xterm\n",
            "Will Install htop\n",
            "Will Install i3\n",
            "Will Install xloadimage\n",
            "Will Install libgtk2.0-0\n",
            "Will Install libgconf-2-4\n",
            "Cloning into 'virtualhome'...\n",
            "remote: Enumerating objects: 27136, done.\u001b[K\n",
            "remote: Counting objects: 100% (520/520), done.\u001b[K\n",
            "remote: Compressing objects: 100% (380/380), done.\u001b[K\n",
            "remote: Total 27136 (delta 347), reused 255 (delta 136), pack-reused 26616\u001b[K\n",
            "Receiving objects: 100% (27136/27136), 249.98 MiB | 28.59 MiB/s, done.\n",
            "Resolving deltas: 100% (17616/17616), done.\n",
            "/content/virtualhome\n",
            "Collecting certifi==2019.3.9\n",
            "  Downloading certifi-2019.3.9-py2.py3-none-any.whl (158 kB)\n",
            "\u001b[K     |████████████████████████████████| 158 kB 5.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet==3.0.4 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (3.0.4)\n",
            "Collecting idna==2.8\n",
            "  Downloading idna-2.8-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (1.21.5)\n",
            "Collecting opencv-python>=4.2.0.32\n",
            "  Downloading opencv_python-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 60.5 MB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (7.1.2)\n",
            "Collecting requests==2.21.0\n",
            "  Downloading requests-2.21.0-py2.py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor==1.1.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (1.1.0)\n",
            "Collecting tqdm==4.31.1\n",
            "  Downloading tqdm-4.31.1-py2.py3-none-any.whl (48 kB)\n",
            "\u001b[K     |████████████████████████████████| 48 kB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (1.24.3)\n",
            "Collecting plotly==3.10\n",
            "  Downloading plotly-3.10.0-py2.py3-none-any.whl (41.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 41.5 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting networkx==2.3\n",
            "  Downloading networkx-2.3.zip (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 34.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from plotly==3.10->-r requirements.txt (line 11)) (2018.9)\n",
            "Collecting retrying>=1.3.3\n",
            "  Downloading retrying-1.3.3.tar.gz (10 kB)\n",
            "Requirement already satisfied: nbformat>=4.2 in /usr/local/lib/python3.7/dist-packages (from plotly==3.10->-r requirements.txt (line 11)) (5.1.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from plotly==3.10->-r requirements.txt (line 11)) (1.15.0)\n",
            "Requirement already satisfied: decorator>=4.0.6 in /usr/local/lib/python3.7/dist-packages (from plotly==3.10->-r requirements.txt (line 11)) (4.4.2)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2->plotly==3.10->-r requirements.txt (line 11)) (4.3.3)\n",
            "Requirement already satisfied: traitlets>=4.1 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2->plotly==3.10->-r requirements.txt (line 11)) (5.1.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2->plotly==3.10->-r requirements.txt (line 11)) (0.2.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2->plotly==3.10->-r requirements.txt (line 11)) (4.9.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2->plotly==3.10->-r requirements.txt (line 11)) (4.11.2)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2->plotly==3.10->-r requirements.txt (line 11)) (5.4.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2->plotly==3.10->-r requirements.txt (line 11)) (21.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2->plotly==3.10->-r requirements.txt (line 11)) (3.10.0.2)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2->plotly==3.10->-r requirements.txt (line 11)) (0.18.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema!=2.5.0,>=2.4->nbformat>=4.2->plotly==3.10->-r requirements.txt (line 11)) (3.7.0)\n",
            "Building wheels for collected packages: networkx, retrying\n",
            "  Building wheel for networkx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for networkx: filename=networkx-2.3-py2.py3-none-any.whl size=1556008 sha256=e54296494e40a45315585d2bb2a56effc0add3a19d3129bcd5319879df404eb3\n",
            "  Stored in directory: /root/.cache/pip/wheels/44/e6/b8/4efaab31158e9e9ca9ed80b11f6b11130bac9a9672b3cbbeaf\n",
            "  Building wheel for retrying (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for retrying: filename=retrying-1.3.3-py3-none-any.whl size=11447 sha256=b94979a173dac70eed010cf79b3d27e8347bad3acf3ad7b48b391352b75767b6\n",
            "  Stored in directory: /root/.cache/pip/wheels/f9/8d/8d/f6af3f7f9eea3553bc2fe6d53e4b287dad18b06a861ac56ddf\n",
            "Successfully built networkx retrying\n",
            "Installing collected packages: idna, certifi, retrying, requests, tqdm, plotly, opencv-python, networkx\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 2.10\n",
            "    Uninstalling idna-2.10:\n",
            "      Successfully uninstalled idna-2.10\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2021.10.8\n",
            "    Uninstalling certifi-2021.10.8:\n",
            "      Successfully uninstalled certifi-2021.10.8\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.63.0\n",
            "    Uninstalling tqdm-4.63.0:\n",
            "      Successfully uninstalled tqdm-4.63.0\n",
            "  Attempting uninstall: plotly\n",
            "    Found existing installation: plotly 5.5.0\n",
            "    Uninstalling plotly-5.5.0:\n",
            "      Successfully uninstalled plotly-5.5.0\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.1.2.30\n",
            "    Uninstalling opencv-python-4.1.2.30:\n",
            "      Successfully uninstalled opencv-python-4.1.2.30\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 2.6.3\n",
            "    Uninstalling networkx-2.6.3:\n",
            "      Successfully uninstalled networkx-2.6.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "spacy 2.2.4 requires tqdm<5.0.0,>=4.38.0, but you have tqdm 4.31.1 which is incompatible.\n",
            "panel 0.12.1 requires tqdm>=4.48.0, but you have tqdm 4.31.1 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.21.0 which is incompatible.\n",
            "fbprophet 0.7.1 requires tqdm>=4.36.1, but you have tqdm 4.31.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "cufflinks 0.17.3 requires plotly>=4.1.1, but you have plotly 3.10.0 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed certifi-2019.3.9 idna-2.8 networkx-2.3 opencv-python-4.5.5.64 plotly-3.10.0 requests-2.21.0 retrying-1.3.3 tqdm-4.31.1\n"
          ]
        }
      ],
      "source": [
        "if 'google.colab' in str(get_ipython()):\n",
        "  print('Running on CoLab')\n",
        "  !pip install git+https://github.com/xavierpuigf/colabstreamer\n",
        "  import colabstreamer\n",
        "  colabstreamer.config_all()\n",
        "  _xorg = colabstreamer.open_xorg()\n",
        "  # Clone VirtualHome\n",
        "  !git clone https://github.com/xavierpuigf/virtualhome.git\n",
        "  %cd /content/virtualhome\n",
        "  !pip install -r requirements.txt\n",
        "else:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdsOviOROaBf"
      },
      "source": [
        "## Download the simulator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJssGx5kOZgu",
        "outputId": "ea6b6b44-9847-4eb8-dc38-0cb950ec06a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-17 17:44:05--  http://virtual-home.org/release/simulator/v2.0/v2.3.0/linux_exec.zip\n",
            "Resolving virtual-home.org (virtual-home.org)... 128.30.100.223\n",
            "Connecting to virtual-home.org (virtual-home.org)|128.30.100.223|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 287737633 (274M) [application/zip]\n",
            "Saving to: ‘linux_exec.zip’\n",
            "\n",
            "linux_exec.zip      100%[===================>] 274.41M  3.80MB/s    in 58s     \n",
            "\n",
            "2022-03-17 17:45:03 (4.75 MB/s) - ‘linux_exec.zip’ saved [287737633/287737633]\n",
            "\n",
            "/content/virtualhome/demo\n"
          ]
        }
      ],
      "source": [
        "! wget http://virtual-home.org/release/simulator/v2.0/v2.3.0/linux_exec.zip\n",
        "! unzip -q linux_exec.zip\n",
        "% cd demo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4AG_awMOyLG"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "UvwB2FFMOzbe"
      },
      "outputs": [],
      "source": [
        "%matplotlib notebook\n",
        "import IPython.display\n",
        "import glob\n",
        "from utils_demo import *\n",
        "from sys import platform\n",
        "import sys\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "sys.path.append('../simulation')\n",
        "from unity_simulator.comm_unity import UnityCommunication\n",
        "from unity_simulator import utils_viz\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jab1StRnN5II"
      },
      "source": [
        "# Starting communication"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0mcWBA9N5IJ"
      },
      "source": [
        "The first step is to start a communication with the simulator. Make sure before you run this that you have downloaded the simulator, and placed it under the `simulation` folder. You will be interacting with the simulator with the communication `comm` created here. You can include the file name of the simulator or just call `UnityCommunication()` and manually open the executable.\n",
        "\n",
        "Select `manual` if you are opening the executable separately, and `auto` if the unity executable is still not open"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1e_kN_sN5IJ",
        "outputId": "2645a019-c730-46e0-effa-f0634de34f68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/virtualhome/demo/../linux_exec.v2.3.0.x86_64', '-batchmode', '-http-port=8082', '-logFile /content/virtualhome/demo/Player_8082.log']\n",
            "Getting connection...\n"
          ]
        }
      ],
      "source": [
        "mode = 'auto' # auto / manual\n",
        "if mode == 'auto':\n",
        "    if platform == 'darwin':\n",
        "        exec_file = '../macos_exec*'\n",
        "    else:\n",
        "        exec_file = '../linux_exec*.x86_64'\n",
        "    file_name = glob.glob(exec_file)[0]\n",
        "    comm = UnityCommunication(file_name=exec_file, port=\"8082\", x_display=\"0\")\n",
        "else:\n",
        "    comm = UnityCommunication()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPouJsE1N5IJ"
      },
      "source": [
        "# Starting and Visualizing Scenes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDOAeyljN5IK"
      },
      "source": [
        "After initalizing the simulation. We can interact with the environments provided in VirtualHome. The simulator is composed of 50 human designed apartments, a sample of environments can be seen here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "W1aqfXaPN5IK",
        "outputId": "8034b867-3f59-4525-916e-86f4ca6909fb",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-1aed62c1c69a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# We will go over the line below later\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mcomm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove_terrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mtop_view\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_scene_cameras\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mviews\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtop_view\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'UnityCommunication' object has no attribute 'remove_terrain'"
          ]
        }
      ],
      "source": [
        "# The environments are numbered 0 to 50, let's visualize a few\n",
        "views = []\n",
        "for scene_id in tqdm(range(10)):\n",
        "    comm.reset(scene_id)\n",
        "    \n",
        "    # We will go over the line below later\n",
        "    comm.remove_terrain()\n",
        "    top_view = get_scene_cameras(comm, [-1])\n",
        "    views += top_view\n",
        "    \n",
        "IPython.display.display(display_grid_img(views, nrows=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GC5FTvmGN5IL"
      },
      "source": [
        "# Procedural Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVuvEXewN5IL"
      },
      "source": [
        "VirtualHome also has support for procedural generation where we can generate completely new environments during runtime."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUZ2UgaFN5IL",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "views = []\n",
        "for proc_gen_seed in tqdm(range(10)):\n",
        "    comm.procedural_generation(proc_gen_seed)\n",
        "    \n",
        "    # We will go over the line below later\n",
        "    comm.remove_terrain()\n",
        "    top_view = get_scene_cameras(comm, [-1])\n",
        "    views += top_view\n",
        "    \n",
        "IPython.display.display(display_grid_img(views, nrows=2)) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_sFFUhBN5IM"
      },
      "source": [
        "## Scene start and display"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcKOGV6ON5IM"
      },
      "source": [
        "We will start scene number 4 and visualize it from different views. We start it by calling reset. Scenes are numbered from 0 to 49."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "41DAoBDwN5IM",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "comm.reset(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWBghzyyN5IM"
      },
      "source": [
        "Each scene has multiple cameras, we will take screenshots for some of the cameras in this scene, specified by indices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-QyzDseN5IN",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "indices = [3, 32, -5, -1, -20, 15, 48, -8, 50, 17]\n",
        "img_final = display_scene_cameras(comm, indices, nrows=2)\n",
        "IPython.display.display(img_final)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I21p9ms8N5IN"
      },
      "source": [
        "## VirtualHome supports multiple modalities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eJiJ9wnN5IN"
      },
      "source": [
        "The cameras can also display other modalities, such as semantic segmentation, depth, instance segmentation or optical flow when playing videos. We will display a few of those here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D9FLzs_SN5IN"
      },
      "outputs": [],
      "source": [
        "indices = [-20, 15, 48, -8, 17]\n",
        "img_final = display_scene_modalities(\n",
        "    comm, \n",
        "    indices, \n",
        "    modalities=['normal', 'seg_class', 'seg_inst', 'depth', 'surf_normals'], nrows=5)\n",
        "IPython.display.display(img_final)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1g-769jJN5IO"
      },
      "source": [
        "## Including cameras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMLmfDZnN5IO"
      },
      "source": [
        "You can also add new cameras in the scene and get screenshots from those"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZdHuQ_aN5IO"
      },
      "outputs": [],
      "source": [
        "# specify the position and rotation of the camera\n",
        "comm.add_camera(position=[0,1.8,0], rotation=[20, 120, 0], field_view=60)\n",
        "\n",
        "# Get the last camera\n",
        "s, c = comm.camera_count()\n",
        "img_final = display_scene_cameras(comm, [c-1], nrows=1)\n",
        "IPython.display.display(img_final)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aG3PDQH7N5IO"
      },
      "source": [
        "We can also update existing cameras, here we will update the camera we just added"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4PhTHqeIN5IO"
      },
      "outputs": [],
      "source": [
        "# specify the position and rotation of the camera\n",
        "comm.update_camera(c-1, position=[0,1.8,0], rotation=[20, 120, 0], field_view=80)\n",
        "\n",
        "# Get the last camera\n",
        "s, c = comm.camera_count()\n",
        "img_final = display_scene_cameras(comm, [c-1], nrows=1)\n",
        "IPython.display.display(img_final)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppePPEg-N5IQ"
      },
      "source": [
        "## Visualizing the scene as a graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0-ZN01aN5IQ"
      },
      "source": [
        "Each scene in VirtualHome can be visualized as a graph, allowing to query the objects appearing, and their relationships. We start by obtaining the graph from the current scene."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S0rEAV2yN5IQ"
      },
      "outputs": [],
      "source": [
        "s, graph = comm.environment_graph()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWaCZEDRN5IQ"
      },
      "source": [
        "The graph is a dictionary with `nodes` and `edges`. Each node corresponds to an object and contains information such as.\n",
        "- class_name: the object_name\n",
        "- states: in which state the object is\n",
        "- id: a number you can use to perform actions over the object "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-PyrMKYN5IR"
      },
      "source": [
        "Let's print one of the nodes, to see more of the information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rK0U8eqSN5IR"
      },
      "outputs": [],
      "source": [
        "graph['nodes'][140]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V54CKD49N5IR"
      },
      "source": [
        "The edges connect object ids with spatial relationships, such as `INSIDE`, `ON`, `CLOSE`. You can check more of them in the `simulation` folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6RMKoOiVN5IR"
      },
      "outputs": [],
      "source": [
        "graph['edges'][:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3TpzZtcN5IR"
      },
      "source": [
        "The graph also contains bounding box and center information, which may be useful to reason about the environment layout."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnzYR9sEN5IR"
      },
      "source": [
        "# Modifying your environment and preparing for activities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZvRC_N4N5IR"
      },
      "source": [
        "In the previous section we viewed how to read and visualize the environment. Now we are interested in modifying the environment to perform activities in them. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIepBZWhN5IS"
      },
      "source": [
        "## Get default environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JH1-Ow5sN5IS"
      },
      "source": [
        "All the environments have a default setting. We can go to this setting by calling reset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x8hBRTi5N5IS"
      },
      "outputs": [],
      "source": [
        "comm.reset(4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06sZZIwiN5IS"
      },
      "source": [
        "## Adding Objects"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8-yquU5N5IS"
      },
      "source": [
        "We will start by adding objects to interact with in the environments. We can start by adding a cat in the environment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyViMtDrN5IS"
      },
      "source": [
        "### Adding a cat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atjSQFBEN5IS"
      },
      "source": [
        "We first want to make sure that the cat will be added in the current environment. Let's say that we want to add it in one of the sofas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mMO-9UqkN5IS"
      },
      "outputs": [],
      "source": [
        "imgs_prev = get_scene_cameras(comm, [-4])\n",
        "display_grid_img(imgs_prev, nrows=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFEL6SIbN5IT"
      },
      "source": [
        "We start by reading the graph and looking for one of the sodas in the scene."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRpsdOeJN5IT"
      },
      "outputs": [],
      "source": [
        "success, graph = comm.environment_graph();\n",
        "sofa = find_nodes(graph, class_name='sofa')[-2]\n",
        "print(sofa)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8a745N9N5IT"
      },
      "source": [
        "We now add one node with id `1000` of type cat, and an edge between the sofa node and the cat, specifying that the cat should be on the sofa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gPNFt930N5IT"
      },
      "outputs": [],
      "source": [
        "add_node(graph, {'class_name': 'cat', \n",
        "                   'category': 'Animals', \n",
        "                   'id': 1000, \n",
        "                   'properties': [], \n",
        "                   'states': []})\n",
        "add_edge(graph, 1000, 'ON', sofa['id'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8o2_SeZN5IT"
      },
      "source": [
        "#### Update environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMvZ0f3YN5IT"
      },
      "source": [
        "The graph is now updated, but now we have to call the simulator so that the environment gets updated with the graph. Let's do it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W29Kocw-N5IT"
      },
      "outputs": [],
      "source": [
        "success, message = comm.expand_scene(graph)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "779G93RHN5IU"
      },
      "source": [
        "You can now take an image of the environment, you will see how there has been a cat added in the environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bhzWIX5CN5IU"
      },
      "outputs": [],
      "source": [
        "imgs_final = get_scene_cameras(comm, [-4])\n",
        "display_grid_img(imgs_prev+imgs_final, nrows=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xgv6yixUN5IU"
      },
      "outputs": [],
      "source": [
        "imgs_prev = imgs_final"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ol-mDuAZN5IU"
      },
      "source": [
        "### Opening fridge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tn_nS_IDN5IU"
      },
      "source": [
        "We may not want to add any new object, but just to change the state of the current objects. We can do this very similarly, by changing the environment graph. Let's say we want to open the fridge."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyV7-2TyN5IU"
      },
      "source": [
        "We read again the graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AwevJDHBN5IU",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "success, graph = comm.environment_graph();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sN_gfPN1N5IV"
      },
      "source": [
        "We find the node `fridge` and change its `states` to open. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kn0oa26HN5IV"
      },
      "outputs": [],
      "source": [
        "fridge = find_nodes(graph, class_name='fridge')[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84U8D0Y8N5IV"
      },
      "outputs": [],
      "source": [
        "fridge['states'] = ['OPEN']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9hjys1dN5IV"
      },
      "source": [
        "We finally expand the graph, as we did before."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2wtU7a4N5IV"
      },
      "outputs": [],
      "source": [
        "success = comm.expand_scene(graph)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LUhaf6klN5IV"
      },
      "outputs": [],
      "source": [
        "imgs_final = get_scene_cameras(comm, [-4])\n",
        "display_grid_img(imgs_prev+imgs_final, nrows=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7pbG2qDN5IV"
      },
      "source": [
        "### Appliances"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SP2Sb65XN5IV"
      },
      "source": [
        "We will use the same method as before to change the state of some appliances. Again just by modifying the state of the graph."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XT6E3fzN5IV"
      },
      "source": [
        "We take a picture of the apartment to see how it looks before doing any change"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NzzBo1r1N5IW"
      },
      "outputs": [],
      "source": [
        "indices = [0]\n",
        "imgs_prev = get_scene_cameras(comm, indices)\n",
        "display_grid_img(imgs_prev, nrows=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqrCi7bxN5IW"
      },
      "source": [
        "We now get the graph of the environment, and select a TV and a light"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k7K69BNNN5IW"
      },
      "outputs": [],
      "source": [
        "success, graph = comm.environment_graph()\n",
        "prev_graph = graph\n",
        "tv_node = [x for x in graph['nodes'] if x['class_name'] == 'tv'][0]\n",
        "light_node = [x for x in graph['nodes'] if x['class_name'] == 'lightswitch'][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvUKDsp2N5IW"
      },
      "source": [
        "We change the state and modify the scene with the new graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1bupD9nN5IW"
      },
      "outputs": [],
      "source": [
        "tv_node['states'] = ['ON']\n",
        "light_node['states'] = ['OFF']\n",
        "_ = comm.expand_scene(graph)\n",
        "last_graph = graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsgoRwzGN5IW"
      },
      "source": [
        "We visualize the final scene"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7_uO-2zAN5IW",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "imgs_final = get_scene_cameras(comm, indices)\n",
        "display_grid_img(imgs_prev+imgs_final, nrows=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3khYQqbtN5IW"
      },
      "source": [
        "### Setting up time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djcJnIuaN5IW"
      },
      "source": [
        "VirtualHome also includes a real-time management system based on the 24 hour system and assign tasks to agents depending on the time of day. Furthermore the time also affects the sun's position in the sky which has a direct effect on the outdoor lighting and indoor lighting through the windows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gq05DwrPN5IW"
      },
      "outputs": [],
      "source": [
        "comm.reset(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FW0pGJodN5IX"
      },
      "outputs": [],
      "source": [
        "views = []\n",
        "s, message = comm.add_camera(position=[-9.2,1.3,-3], rotation=[15, 130, 0], field_view=60)\n",
        "cam_id = int(message.split(':')[1])\n",
        "# Set time to 05:30 \n",
        "comm.set_time(hours=10, minutes=30, seconds=0)\n",
        "morning_view = get_scene_cameras(comm, [cam_id])\n",
        "views += morning_view\n",
        "\n",
        "# Set time to 8:30 \n",
        "comm.set_time(hours=15, minutes=30, seconds=0)\n",
        "day_view = get_scene_cameras(comm, [cam_id])\n",
        "views += day_view\n",
        "\n",
        "# Set time to 21:00 \n",
        "comm.set_time(hours=21, minutes=0, seconds=0)\n",
        "night_view = get_scene_cameras(comm, [cam_id])\n",
        "views += night_view\n",
        "    \n",
        "IPython.display.display(display_grid_img(views, nrows=1)) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVkeXDrQN5IX"
      },
      "source": [
        "We can also deactivate the time and the forests outside, if we want"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Iztc6dzN5IX"
      },
      "outputs": [],
      "source": [
        "comm.reset(0)\n",
        "comm.remove_terrain()\n",
        "no_day_view = get_scene_cameras(comm, [17])\n",
        "IPython.display.display(display_grid_img(no_day_view, nrows=1)) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydMBom8LN5IX"
      },
      "source": [
        "# Generating Scripts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfJm-yIgN5IX"
      },
      "source": [
        "We now can start scenes, visualize them and modify them. The last step is to perform activities in them. We do this by defining scripts: Lists of instructions that will be executed in sequence. Each instruction contains an action, an object, and an id. The id should match with the `id` of each of the nodes in the environment graph."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npYF5X7WN5IX"
      },
      "source": [
        "You can check the list of actions currently implemented [here](https://github.com/xavierpuigf/virtualhome/tree/master/simulation#actions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sc1rCBGdN5IX"
      },
      "source": [
        "### Adding a character"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjfiAWOXN5IX"
      },
      "source": [
        "The first step is to add agents in the environment, that will be performing the activity. You can specify which agent you want to add and the room where you want to add it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "71ctIkMNN5IX"
      },
      "outputs": [],
      "source": [
        "comm.reset(4)\n",
        "tv_node['states'] = ['OFF']\n",
        "comm.expand_scene(prev_graph)\n",
        "comm.add_character('chars/Female2', initial_room='kitchen')\n",
        "s, g = comm.environment_graph()\n",
        "cat_id = [node['id'] for node in g['nodes'] if node['class_name'] == 'cat'][0]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcqAWdIJN5IY"
      },
      "source": [
        "If you count the number of cameras, you will see that a few new cameras have been added into the scene. These are cameras attached to the character. When the character moves, the cameras will move as well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-yZ_SQkN5IY"
      },
      "outputs": [],
      "source": [
        "s, nc = comm.camera_count()\n",
        "indices = range(nc - 6, nc)\n",
        "imgs_prev = get_scene_cameras(comm, indices)\n",
        "display_grid_img(imgs_prev, nrows=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQbdm9W1N5IY"
      },
      "source": [
        "## Generating the first script"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcLd8kosN5IY"
      },
      "source": [
        "Let's start by interacting witht the cat and the sofa that we set up before. The cat had id 1000. The sofa was stored in a variable `sofa` containing that node. We can query its id directly. This sequence will make the agent walk to the sofa, grab the cat and sit in the sofa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1EY9nbZ8N5IY"
      },
      "outputs": [],
      "source": [
        "script = ['<char0> [Walk] <sofa> ({})'.format(sofa['id']),\n",
        "          '<char0> [Find] <cat> ({})'.format(cat_id),\n",
        "          '<char0> [Grab] <cat> ({})'.format(cat_id),\n",
        "          '<char0> [Sit] <sofa> ({})'.format(sofa['id'])]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZM7Q12vIN5IY"
      },
      "source": [
        "We now want to execute the script in the environment. We do that through render_script. Notice that we can specify a file name, which will be used to save a video with the activity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXE7EYKJN5IY"
      },
      "outputs": [],
      "source": [
        "success, message = comm.render_script(script=script,\n",
        "                                      processing_time_limit=60,\n",
        "                                      find_solution=False,\n",
        "                                      image_width=320,\n",
        "                                      image_height=240,  \n",
        "                                      skip_animation=False,\n",
        "                                      recording=True,\n",
        "                                      save_pose_data=True,\n",
        "                                      file_name_prefix='relax')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lleTVLeIN5Ia"
      },
      "source": [
        "This saves the frames of the video into the `Output/relax` folder, which should be where you had your executable. Let's generate a video from the frames."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gjUmQCOBN5Ia"
      },
      "outputs": [],
      "source": [
        "# Enter here the path to the video, it should be in the same location where you stored your executable \n",
        "path_video = \"../simulation/Output/\"\n",
        "utils_viz.generate_video(input_path=path_video, prefix='relax', output_path='.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8q7YTLwIN5Ia"
      },
      "outputs": [],
      "source": [
        "display_vid('./video_normal.mp4')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_QMgXA2N5Ia"
      },
      "source": [
        "Other paramters to render_script are:\n",
        "- script: a list of script lines\n",
        "- randomize_execution: randomly choose elements\n",
        "- random_seed: random seed to use when randomizing execution, -1 means that the seed is not set\n",
        "- find_solution: find solution (True) or use graph ids to determine object instances (False)\n",
        "- processing_time_limit: time limit for finding a solution\n",
        "- skip_execution: skip rendering, only check if a solution exists\n",
        "- output_folder: folder to output renderings, default is Output/\n",
        "- file_name_prefix: prefix of created files (screenshots are put to output_folder/file_name_prefix/)\n",
        "- frame_rate: frame rate\n",
        "- capture_screenshot: save screenshots\n",
        "- image_synthesis: save depth, segmentation, flow images\n",
        "- save_pose_data: save pose data\n",
        "- save_scene_states: save scene states\n",
        "- character_resource: path to character resource to be used\n",
        "- camera_mode: automatic (AUTO), first person (FIRST_PERSON), top (PERSON_TOP), front person view (PERSON_FRONT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bmWfktL0N5Ia"
      },
      "outputs": [],
      "source": [
        "# We can also visualize the skeleton\n",
        "\n",
        "path_video = \"../simulation/Output/\"\n",
        "pose_char, frames = utils_viz.get_skeleton(input_path=path_video, prefix='relax')\n",
        "ax = plt.axes(projection='3d')\n",
        "frame = 40\n",
        "center_char = pose_char.mean(1)\n",
        "ax.scatter3D(pose_char[frame, :, 0], pose_char[frame, :, 2], pose_char[frame, :, 1])\n",
        "ax.set_xlim(center_char[frame, 0]-0.8, center_char[frame, 0] + 0.8)\n",
        "ax.set_ylim(center_char[frame, 2]-0.8, center_char[frame, 2] + 0.8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aFCZyZEN5Ia"
      },
      "source": [
        "## Generating a script without a video"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CySj8iO6N5Ia"
      },
      "source": [
        "In some occasions you may not be interested in generating a full video for the script, for example if you want to do RL. You can run the script withtout rendering a video by setting image_synthesis to empty. This will execute the script much more quickly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dw0RFxVEN5Ib"
      },
      "source": [
        "Restart the previous graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hISdG-pAN5Ib"
      },
      "outputs": [],
      "source": [
        "comm.reset(4)\n",
        "comm.expand_scene(prev_graph)\n",
        "comm.add_character()\n",
        "s, g = comm.environment_graph()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwQNIYF5N5Ib"
      },
      "source": [
        "Run with `image_synthesis=[]`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4tO_3w9N5Ib"
      },
      "outputs": [],
      "source": [
        "success, message = comm.render_script(script=script,\n",
        "                                      processing_time_limit=60,\n",
        "                                      find_solution=False,\n",
        "                                      image_synthesis=[])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuu1Kv0zN5Ib"
      },
      "source": [
        "## Generating from multiple views"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QknfFkyN5Ib"
      },
      "source": [
        "We can chose which camera to use while rendering the videos. This is done through the flag `CAMERA_MODE`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RHq1UIjBN5Ib"
      },
      "outputs": [],
      "source": [
        "comm.reset(4)\n",
        "_, _ = comm.expand_scene(last_graph)\n",
        "comm.add_character()\n",
        "success, message = comm.render_script(script=script,\n",
        "                                      processing_time_limit=60,\n",
        "                                      find_solution=False,\n",
        "                                      recording=True,\n",
        "                                      image_synthesis=['normal'],\n",
        "                                      file_name_prefix='multiview',\n",
        "                                      camera_mode=['FIRST_PERSON', 'PERSON_TOP'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65XofHrwN5Ib"
      },
      "source": [
        "You can specify camera names, for cameras that will follow the character or camera indices, for static cameras. To get the list of camera names, call character_cameras:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k9887wX5N5Ib"
      },
      "outputs": [],
      "source": [
        "comm.character_cameras()[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAv1XsYRN5Ib"
      },
      "source": [
        "## Generating underspecified videos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFuDX6rhN5Ic"
      },
      "source": [
        "If we do not care which objects the simulator should interact with, we can also let it decide. If we use the flag `find_solution=True` we can start enumerating objects by `1` instead of following the graph ids. Unity will try to find a solution. Note that if we want to interact with 2 objects of the same kind, they will need to have different ids (i.e. 1 and 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Md-o4P2N5Ic",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "comm.reset(6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v2ZfmPdpN5Ic"
      },
      "outputs": [],
      "source": [
        "s, g = comm.environment_graph()\n",
        "[node for node in g['nodes'] if node['class_name'] == 'milk']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJGstzheN5Ic"
      },
      "outputs": [],
      "source": [
        "comm.add_character()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jv3feYdpN5Ic"
      },
      "outputs": [],
      "source": [
        "script = ['<char0> [walk] <milk> (1)',\n",
        "          '<char0> [grab] <milk> (1)',\n",
        "          '<char0> [walk] <microwave> (1)',\n",
        "          '<char0> [open] <microwave> (1)',\n",
        "          '<char0> [putin] <milk> (1) <microwave> (1)',\n",
        "          '<char0> [close] <microwave> (1)',\n",
        "          '<char0> [switchon] <microwave> (1)']\n",
        "          \n",
        "success, message = comm.render_script(script=script, \n",
        "                                      find_solution=True,\n",
        "                                      processing_time_limit=80,\n",
        "                                      frame_rate=15,\n",
        "                                      image_width=512, image_height=320,\n",
        "                                      skip_animation=False,\n",
        "                                      image_synthesis=['normal'],\n",
        "                                      camera_mode=['PERSON_FROM_BACK'],\n",
        "                                      recording=True,\n",
        "                                      file_name_prefix='milk')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5efHIy_HN5Ic"
      },
      "source": [
        "# Multi-agent Actions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYW6D8FVN5Ic"
      },
      "source": [
        "You can also generate actions with multiple agents in them, simply add more agents, and specify which agents should do which action"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WayXfhd2N5Ic"
      },
      "outputs": [],
      "source": [
        "# Reset the scene\n",
        "comm.reset(0)\n",
        "s, g = comm.environment_graph()\n",
        "# Add two agents this time\n",
        "comm.add_character('Chars/Male2', initial_room='kitchen')\n",
        "comm.add_character('Chars/Female4', initial_room='bedroom')\n",
        "\n",
        "# Get nodes for salmon and microwave, glass, faucet and sink\n",
        "salmon_id = [node['id'] for node in g['nodes'] if node['class_name'] == 'salmon'][0]\n",
        "microwave_id = [node['id'] for node in g['nodes'] if node['class_name'] == 'microwave'][0]\n",
        "glass_id = [node['id'] for node in g['nodes'] if node['class_name'] == 'waterglass'][-1]\n",
        "sink_id = [node['id'] for node in g['nodes'] if node['class_name'] == 'sink'][0]\n",
        "faucet_id = [node['id'] for node in g['nodes'] if node['class_name'] == 'faucet'][-1]\n",
        "\n",
        "\n",
        "# Put salmon in microwave\n",
        "script = [\n",
        "    '<char0> [walk] <salmon> ({}) | <char1> [walk] <glass> ({})'.format(salmon_id, glass_id),\n",
        "    '<char0> [grab] <salmon> ({}) | <char1> [grab] <glass> ({})'.format(salmon_id, glass_id),\n",
        "    '<char0> [open] <microwave> ({}) | <char1> [walk] <sink> ({})'.format(microwave_id, sink_id),\n",
        "    '<char0> [putin] <salmon> ({}) <microwave> ({}) | <char1> [putback] <glass> ({}) <sink> ({})'.format(salmon_id, microwave_id, glass_id, sink_id),\n",
        "    '<char0> [close] <microwave> ({}) | <char1> [switchon] <faucet> ({})'.format(microwave_id, faucet_id)\n",
        "]\n",
        "comm.render_script(script, frame_rate=10, camera_mode=[\"PERSON_FROM_BACK\"], recording=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZabO3ZjDN5Ic"
      },
      "source": [
        "# Interactive agents\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euFGRIbmN5Ic"
      },
      "source": [
        "So far we have seen how to generate videos, but we can use the same command to deploy or train agents in the environment. You can execute the previous instructions one by one, and get an observation or graph at every step. or that, you don't need to generate videos or have animations, since it will slow down your agents. Use `skip_animation=True` to generate actions without animating them. Remember to turn off the recording mode as well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMlhdT73N5Id"
      },
      "outputs": [],
      "source": [
        "# Reset the scene\n",
        "comm.reset(0)\n",
        "\n",
        "# Add two agents this time\n",
        "comm.add_character('Chars/Male2', initial_room='kitchen')\n",
        "comm.add_character('Chars/Female4', initial_room='bedroom')\n",
        "\n",
        "# Get nodes for salmon and microwave, glass, faucet and sink\n",
        "salmon_id = [node['id'] for node in g['nodes'] if node['class_name'] == 'salmon'][0]\n",
        "microwave_id = [node['id'] for node in g['nodes'] if node['class_name'] == 'microwave'][0]\n",
        "glass_id = [node['id'] for node in g['nodes'] if node['class_name'] == 'waterglass'][-1]\n",
        "sink_id = [node['id'] for node in g['nodes'] if node['class_name'] == 'sink'][0]\n",
        "faucet_id = [node['id'] for node in g['nodes'] if node['class_name'] == 'faucet'][-1]\n",
        "\n",
        "\n",
        "# Put salmon in microwave\n",
        "script = [\n",
        "    '<char0> [walk] <salmon> ({}) | <char1> [walk] <glass> ({})'.format(salmon_id, glass_id),\n",
        "    '<char0> [grab] <salmon> ({}) | <char1> [grab] <glass> ({})'.format(salmon_id, glass_id),\n",
        "    '<char0> [open] <microwave> ({}) | <char1> [walk] <sink> ({})'.format(microwave_id, sink_id),\n",
        "    '<char0> [putin] <salmon> ({}) <microwave> ({}) | <char1> [putback] <glass> ({}) <sink> ({})'.format(salmon_id, microwave_id, glass_id, sink_id),\n",
        "    '<char0> [close] <microwave> ({}) | <char1> [switchon] <faucet> ({})'.format(microwave_id, faucet_id)\n",
        "]\n",
        "\n",
        "s, cc = comm.camera_count()\n",
        "images = []\n",
        "for script_instruction in script:\n",
        "    print(script_instruction)\n",
        "    comm.render_script([script_instruction], recording=False, skip_animation=True)\n",
        "    # Here you can get an observation, for instance\n",
        "    s, im = comm.camera_image([cc-8], image_width=300, image_height=300)\n",
        "    images.append(im[0])\n",
        "    \n",
        "display_grid_img(images, nrows=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZoLqoeVN5Id"
      },
      "source": [
        "# Finer control"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXnOjakTN5Id"
      },
      "source": [
        "We can also have finer control where objects go via action modifiers, the demo below shows how to place an object in different parts of the table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46zuAup4N5Id"
      },
      "outputs": [],
      "source": [
        "comm.reset(0)\n",
        "s, g = comm.environment_graph()\n",
        "# Remove stuff from the table and add the character\n",
        "table = [node for node in g['nodes'] if node['class_name'] == 'kitchentable'][0]\n",
        "mouse = [node for node in g['nodes'] if node['class_name'] == 'mouse'][0]\n",
        "mouse_id = mouse['id']\n",
        "table_id = table['id']\n",
        "\n",
        "objects_on_table = [edge['from_id'] for edge in g['edges'] \n",
        "                    if edge['to_id'] == table['id'] and edge['relation_type'] == 'ON']\n",
        "new_graph = {\n",
        "    'nodes': [node for node in g['nodes'] if node['id'] not in objects_on_table],\n",
        "    'edges': [edge for edge in g['edges'] if edge['from_id'] not in objects_on_table and \n",
        "                                             edge['to_id'] not in objects_on_table]\n",
        "}\n",
        "\n",
        "comm.expand_scene(new_graph)\n",
        "comm.add_character()\n",
        "\n",
        "# This is to get a camera view on top of the character\n",
        "cc = comm.camera_count()[1] - 7\n",
        "\n",
        "\n",
        "# Start grabbing the mouse and go to the table\n",
        "script1 = [f'<char0> [grab] <mouse> ({mouse_id})', \n",
        "           f'<char0> [walk] <kitchentable> ({table_id})']\n",
        "s, m = comm.render_script(script1, skip_animation=True)\n",
        "\n",
        "images = []\n",
        "\n",
        "# Place the mouse in some position\n",
        "posx, posy = -1.1, -5.5\n",
        "script2 = [f'<char0> [putback] <mouse> ({mouse_id}) <kitchentable> ({table_id}) <position> {posx},{posy}']\n",
        "s, m = comm.render_script(script2, skip_animation=True)\n",
        "s, im1 = comm.camera_image([cc])\n",
        "images.append(im1[0])\n",
        "\n",
        "# Try a different positiom\n",
        "posx, posy = -1.3, -5.1\n",
        "script2 = [f'<char0> [grab] <mouse> ({mouse_id})',\n",
        "           f'<char0> [putback] <mouse> ({mouse_id}) <kitchentable> ({table_id}) <position> {posx},{posy}']\n",
        "s, m = comm.render_script(script2, skip_animation=True)\n",
        "s, im1 = comm.camera_image([cc])\n",
        "images.append(im1[0])\n",
        "\n",
        "display_grid_img(images, nrows=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTDxT1PoN5Id"
      },
      "source": [
        "# Physics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmcKofDAN5Id"
      },
      "source": [
        "VirtualHome is also able to simulate physics in the environments, and you can use the following api call to alter the gravitational force experienced in the environemnt. By activating physics, all objects behave as expected, just like in the real world. However you can also alter the \"g-force\" to make the agent feel like they are a astronaut in space."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rC-ME5wEN5Id"
      },
      "outputs": [],
      "source": [
        "# Reset the scene and get the graph\n",
        "comm.reset(0)\n",
        "s, g = comm.environment_graph()\n",
        "\n",
        "# Add a agent \n",
        "comm.add_character('Chars/female2', initial_room='kitchen')\n",
        "\n",
        "# Get nodes for apple, desk, kitchen\n",
        "apple = [node['id'] for node in g['nodes'] if node['class_name'] == 'apple'][0]\n",
        "desk = [node['id'] for node in g['nodes'] if node['class_name'] == 'desk'][1]\n",
        "kitchen = [node['id'] for node in g['nodes'] if node['class_name'] == 'kitchen'][0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z6-KsiPpN5Id"
      },
      "outputs": [],
      "source": [
        "# Activate gravity\n",
        "comm.activate_physics()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5zYKoMcN5Ie"
      },
      "outputs": [],
      "source": [
        "# Put apple on desk\n",
        "script = [\n",
        "          '<char0> [grab] <apple> ({})'.format(apple),\n",
        "          '<char0> [put] <apple> ({}) <desk> ({})'.format(apple, desk),\n",
        "          '<char0> [walk] <kitchen> ({})'.format(kitchen),\n",
        "          '<char0> [grab] <apple> ({})'.format(apple),\n",
        "          '<char0> [put] <apple> ({}) <desk> ({}  <position> 0,-3)'.format(apple, desk),\n",
        "         ]\n",
        "success, message = comm.render_script(script=script[:2], \n",
        "                                      find_solution=True,\n",
        "                                      processing_time_limit=80,\n",
        "                                      frame_rate=15,\n",
        "                                      image_width=512, image_height=320,\n",
        "                                      skip_animation=False,\n",
        "                                      image_synthesis=['normal'],\n",
        "                                      camera_mode=['58'],\n",
        "                                      recording=True,\n",
        "                                      file_name_prefix='gravity')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "unity_demo.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}