{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo VirtualHome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a demo of how to run VirtualHome UnitySimulator. The demo will walk though how to start an environment and visualize it, how to prepare it to perform activities and finally how to perform activities in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import IPython.display\n",
    "from utils_demo import *\n",
    "from sys import platform\n",
    "import sys\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append('../simulation')\n",
    "from unity_simulator.comm_unity import UnityCommunication\n",
    "from unity_simulator import utils_viz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting communication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to start a communication with the simulator. Make sure before you run this that you have downloaded the simulator, and placed it under the `simulation` folder. You will be interacting with the simulator with the communication `comm` created here. You can include the file name of the simulator or just call `UnityCommunication()` and manually open the executable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'manual' # auto / manual\n",
    "if mode == 'auto':\n",
    "    if platform == 'darwin':\n",
    "        exec_file = '../simulation/macos_exec'\n",
    "    else:\n",
    "        exec_file = '../simulation/exec_linux.x86_64'\n",
    "    comm = UnityCommunication(file_name=exec_file)\n",
    "else:\n",
    "    comm = UnityCommunication()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm = UnityCommunication()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting and Visualizing Scenes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After initalizing the simulation. We can interact with the environments provided in VirtualHome. The simulator is composed of 50 human designed apartments, a sample of environments can be seen here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The environments are numbered 0 to 50, let's visualize a few\n",
    "views = []\n",
    "for scene_id in range(10):\n",
    "    comm.reset(scene_id)\n",
    "    comm.remove_terrain()\n",
    "    top_view = get_scene_cameras(comm, [-1])\n",
    "    views += top_view\n",
    "    \n",
    "IPython.display.display(display_grid_img(views, nrows=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procedural Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VirtualHome also has support for procedural generation where we can generate completely new environments during runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "views = []\n",
    "for proc_gen_seed in range(10):\n",
    "    comm.procedural_generation(proc_gen_seed)\n",
    "    comm.remove_terrain()\n",
    "    top_view = get_scene_cameras(comm, [-1])\n",
    "    views += top_view\n",
    "    \n",
    "IPython.display.display(display_grid_img(views, nrows=2)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scene start and display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start scene number 4 and start visualizing it. We start it by calling reset. Scenes are numbered from 0 to 49."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "comm.reset(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s, im = comm.camera_image([0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each scene has multiple cameras, we will take screenshots for some of the cameras in this scene, specified by indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "indices = [3, 32, -5, -1, -20, 15, 48, -8]\n",
    "img_final = display_scene_cameras(comm, indices, nrows=2)\n",
    "IPython.display.display(img_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VirtualHome supports multiple modalities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cameras can also display other modalities, such as semantic segmentation, depth, instance segmentation or optical flow when playing videos. We will display a few of those here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [-20, 15, 48, -8]\n",
    "img_final = display_scene_modalities(\n",
    "    comm, \n",
    "    indices, \n",
    "    modalities=['normal', 'seg_class', 'seg_inst', 'depth', 'surf_normals'], nrows=5)\n",
    "IPython.display.display(img_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Including cameras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also add new cameras in the scene and get screenshots from those"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the position and rotation of the camera\n",
    "comm.add_camera(position=[0,1.8,0], rotation=[20, 120, 0], focal_length=30)\n",
    "\n",
    "# Get the last camera\n",
    "s, c = comm.camera_count()\n",
    "img_final = display_scene_cameras(comm, [c-1], nrows=1)\n",
    "IPython.display.display(img_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the scene as a graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each scene in VirtualHome can be visualized as a graph, allowing to query the objects appearing, and their relationships. We start by obtaining the graph from the current scene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s, graph = comm.environment_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph is a dictionary with `nodes` and `edges`. Each node corresponds to an object and contains information such as.\n",
    "- class_name: the object_name\n",
    "- states: in which state the object is\n",
    "- id: a number you can use to perform actions over the object "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print one of the nodes, to see more of the information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph['nodes'][140]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The edges connect object ids with spatial relationships, such as `INSIDE`, `ON`, `CLOSE`. You can check more of them in the `simulation` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph['edges'][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph also contains bounding box and center information, which may be useful to reason about the environment layout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modifying your environment and preparing for activities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous section we viewed how to read and visualize the environment. Now we are interested in modifying the environment to perform activities in them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get default environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the environments have a default setting. We can go to this setting by calling reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm.reset(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by adding objects to interact with in the environments. We can start by adding a cat in the environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding a cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first want to make sure that the cat will be added in the current environment. Let's say that we want to add it in one of the sofas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_prev = get_scene_cameras(comm, [-4])\n",
    "display_grid_img(imgs_prev, nrows=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by reading the graph and looking for one of the sodas in the scene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success, graph = comm.environment_graph();\n",
    "sofa = find_nodes(graph, class_name='sofa')[-2]\n",
    "print(sofa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now add one node with id `1000` of type cat, and an edge between the sofa node and the cat, specifying that the cat should be on the sofa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_node(graph, {'class_name': 'cat', \n",
    "                   'category': 'Animals', \n",
    "                   'id': 1000, \n",
    "                   'properties': [], \n",
    "                   'states': []})\n",
    "add_edge(graph, 1000, 'ON', sofa['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph is now updated, but now we have to call the simulator so that the environment gets updated with the graph. Let's do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success, message = comm.expand_scene(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now take an image of the environment, you will see how there has been a cat added in the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_final = get_scene_cameras(comm, [-4])\n",
    "display_grid_img(imgs_prev+imgs_final, nrows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_prev = imgs_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opening fridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may not want to add any new object, but just to change the state of the current objects. We can do this very similarly, by changing the environment graph. Let's say we want to open the fridge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read again the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "success, graph = comm.environment_graph();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find the node `fridge` and change its `states` to open. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fridge = find_nodes(graph, class_name='fridge')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fridge['states'] = ['OPEN']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We finally expand the graph, as we did before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success = comm.expand_scene(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_final = get_scene_cameras(comm, [-4])\n",
    "display_grid_img(imgs_prev+imgs_final, nrows=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appliances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the same method as before to change the state of some appliances. Again just by modifying the state of the graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take a picture of the apartment to see how it looks before doing any change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [0]\n",
    "imgs_prev = get_scene_cameras(comm, indices)\n",
    "display_grid_img(imgs_prev, nrows=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now get the graph of the environment, and select a TV and a light"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success, graph = comm.environment_graph()\n",
    "prev_graph = graph\n",
    "tv_node = [x for x in graph['nodes'] if x['class_name'] == 'tv'][0]\n",
    "light_node = [x for x in graph['nodes'] if x['class_name'] == 'lightswitch'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We change the state and modify the scene with the new graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_node['states'] = ['ON']\n",
    "light_node['states'] = ['OFF']\n",
    "_ = comm.expand_scene(graph)\n",
    "last_graph = graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We visualize the final scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imgs_final = get_scene_cameras(comm, indices)\n",
    "display_grid_img(imgs_prev+imgs_final, nrows=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VirtualHome also includes a real-time management system based on the 24 hour system and assign tasks to agents depending on the time of day. Furthermore the time also affects the sun's position in the sky which has a direct effect on the outdoor lighting and indoor lighting through the windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "comm.reset(0)\n",
    "views = []\n",
    "\n",
    "# Set time to 05:30 \n",
    "comm.set_time(hour=5, minute=30, second=0)\n",
    "morning_view = get_scene_cameras(comm, [17])\n",
    "views += morning_view\n",
    "\n",
    "# Set time to 8:30 \n",
    "comm.set_time(hour=8, minute=30, second=0)\n",
    "day_view = get_scene_cameras(comm, [17])\n",
    "views += day_view\n",
    "\n",
    "# Set time to 21:00 \n",
    "comm.set_time(hour=21, minute=0, second=0)\n",
    "night_view = get_scene_cameras(comm, [17])\n",
    "views += night_view\n",
    "    \n",
    "IPython.display.display(display_grid_img(views, nrows=1)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now can start scenes, visualize them and modify them. The last step is to perform activities in them. We do this by defining scripts: Lists of instructions that will be executed in sequence. Each instruction contains an action, an object, and an id. The id should match with the `id` of each of the nodes in the environment graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check the list of actions currently implemented [here](https://github.com/xavierpuigf/virtualhome/tree/master/simulation#actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding a character"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to add agents in the environment, that will be performing the activity. You can specify which agent you want to add and the room where you want to add it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm.reset(4)\n",
    "tv_node['states'] = ['OFF']\n",
    "comm.expand_scene(prev_graph)\n",
    "comm.add_character('chars/Female2', initial_room='kitchen')\n",
    "s, g = comm.environment_graph()\n",
    "cat_id = [node['id'] for node in g['nodes'] if node['class_name'] == 'cat'][0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you count the number of cameras, you will see that a few new cameras have been added into the scene. These are cameras attached to the character. When the character moves, the cameras will move as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s, nc = comm.camera_count()\n",
    "indices = range(nc - 6, nc)\n",
    "imgs_prev = get_scene_cameras(comm, indices)\n",
    "display_grid_img(imgs_prev, nrows=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the first script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by interacting witht the cat and the sofa that we set up before. The cat had id 1000. The sofa was stored in a variable `sofa` containing that node. We can query its id directly. This sequence will make the agent walk to the sofa, grab the cat and sit in the sofa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script = ['<char0> [Walk] <sofa> ({})'.format(sofa['id']),\n",
    "          '<char0> [Find] <cat> ({})'.format(cat_id),\n",
    "          '<char0> [Grab] <cat> ({})'.format(cat_id),\n",
    "          '<char0> [Sit] <sofa> ({})'.format(sofa['id'])]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want to execute the script in the environment. We do that through render_script. Notice that we can specify a file name, which will be used to save a video with the activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success, message = comm.render_script(script=script,\n",
    "                                      processing_time_limit=60,\n",
    "                                      find_solution=False,\n",
    "                                      image_width=320,\n",
    "                                      image_height=240,  \n",
    "                                      skip_animation=False,\n",
    "                                      recording=True,\n",
    "                                      save_pose_data=True,\n",
    "                                      file_name_prefix='relax')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This saves the frames of the video into the `Output/relax` folder, which should be where you had your executable. Let's generate a video from the frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter here the path to the video, it should be in the same location where you stored your executable \n",
    "path_video = \"../simulation/Output/\"\n",
    "utils_viz.generate_video(input_path=path_video, prefix='relax', output_path='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_vid('./video_normal.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other paramters to render_script are:\n",
    "- script: a list of script lines\n",
    "- randomize_execution: randomly choose elements\n",
    "- random_seed: random seed to use when randomizing execution, -1 means that the seed is not set\n",
    "- find_solution: find solution (True) or use graph ids to determine object instances (False)\n",
    "- processing_time_limit: time limit for finding a solution\n",
    "- skip_execution: skip rendering, only check if a solution exists\n",
    "- output_folder: folder to output renderings, default is Output/\n",
    "- file_name_prefix: prefix of created files (screenshots are put to output_folder/file_name_prefix/)\n",
    "- frame_rate: frame rate\n",
    "- capture_screenshot: save screenshots\n",
    "- image_synthesis: save depth, segmentation, flow images\n",
    "- save_pose_data: save pose data\n",
    "- save_scene_states: save scene states\n",
    "- character_resource: path to character resource to be used\n",
    "- camera_mode: automatic (AUTO), first person (FIRST_PERSON), top (PERSON_TOP), front person view (PERSON_FRONT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also visualize the skeleton\n",
    "\n",
    "path_video = \"../simulation/Output/\"\n",
    "pose_char, frames = utils_viz.get_skeleton(input_path=path_video, prefix='relax')\n",
    "ax = plt.axes(projection='3d')\n",
    "frame = 40\n",
    "center_char = pose_char.mean(1)\n",
    "ax.scatter3D(pose_char[frame, :, 0], pose_char[frame, :, 2], pose_char[frame, :, 1])\n",
    "ax.set_xlim(center_char[frame, 0]-0.8, center_char[frame, 0] + 0.8)\n",
    "ax.set_ylim(center_char[frame, 2]-0.8, center_char[frame, 2] + 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating a script without a video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some occasions you may not be interested in generating a full video for the script, for example if you want to do RL. You can run the script withtout rendering a video by setting image_synthesis to empty. This will execute the script much more quickly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restart the previous graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm.reset(4)\n",
    "comm.expand_scene(prev_graph)\n",
    "comm.add_character()\n",
    "s, g = comm.environment_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run with `image_synthesis=[]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success, message = comm.render_script(script=script,\n",
    "                                      processing_time_limit=60,\n",
    "                                      find_solution=False,\n",
    "                                      image_synthesis=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating from multiple views"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can chose which camera to use while rendering the videos. This is done through the flag `CAMERA_MODE`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm.reset(4)\n",
    "_, _ = comm.expand_scene(last_graph)\n",
    "comm.add_character()\n",
    "success, message = comm.render_script(script=script,\n",
    "                                      processing_time_limit=60,\n",
    "                                      find_solution=False,\n",
    "                                      recording=True,\n",
    "                                      image_synthesis=['normal'],\n",
    "                                      camera_mode=['FIRST_PERSON'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating underspecified videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we do not care which objects the simulator should interact with, we can also let it decide. If we use the flag `find_solution=True` we can start enumerating objects by `1` instead of following the graph ids. Unity will try to find a solution. Note that if we want to interact with 2 objects of the same kind, they will need to have different ids (i.e. 1 and 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "comm.reset(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s, g = comm.environment_graph()\n",
    "[node for node in g['nodes'] if node['class_name'] == 'milk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm.add_character()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script = ['<char0> [walk] <milk> (1)',\n",
    "          '<char0> [grab] <milk> (1)',\n",
    "          '<char0> [walk] <microwave> (1)',\n",
    "          '<char0> [open] <microwave> (1)',\n",
    "          '<char0> [putin] <milk> (1) <microwave> (1)',\n",
    "          '<char0> [close] <microwave> (1)',\n",
    "          '<char0> [switchon] <microwave> (1)']\n",
    "          \n",
    "success, message = comm.render_script(script=script, \n",
    "                                      find_solution=True,\n",
    "                                      processing_time_limit=80,\n",
    "                                      frame_rate=15,\n",
    "                                      image_width=512, image_height=320,\n",
    "                                      skip_animation=False,\n",
    "                                      image_synthesis=['normal'],\n",
    "                                      camera_mode=['PERSON_FROM_BACK'],\n",
    "                                      recording=True,\n",
    "                                      file_name_prefix='milk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-agent Actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also generate actions with multiple agents in them, simply add more agents, and specify which agents should do which action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the scene\n",
    "comm.reset(0)\n",
    "s, g = comm.environment_graph()\n",
    "# Add two agents this time\n",
    "comm.add_character('Chars/Male2', initial_room='kitchen')\n",
    "comm.add_character('Chars/Female4', initial_room='bedroom')\n",
    "\n",
    "# Get nodes for salmon and microwave, glass, faucet and sink\n",
    "salmon_id = [node['id'] for node in g['nodes'] if node['class_name'] == 'salmon'][0]\n",
    "microwave_id = [node['id'] for node in g['nodes'] if node['class_name'] == 'microwave'][0]\n",
    "glass_id = [node['id'] for node in g['nodes'] if node['class_name'] == 'waterglass'][-1]\n",
    "sink_id = [node['id'] for node in g['nodes'] if node['class_name'] == 'sink'][0]\n",
    "faucet_id = [node['id'] for node in g['nodes'] if node['class_name'] == 'faucet'][-1]\n",
    "\n",
    "\n",
    "# Put salmon in microwave\n",
    "script = [\n",
    "    '<char0> [walk] <salmon> ({}) | <char1> [walk] <glass> ({})'.format(salmon_id, glass_id),\n",
    "    '<char0> [grab] <salmon> ({}) | <char1> [grab] <glass> ({})'.format(salmon_id, glass_id),\n",
    "    '<char0> [open] <microwave> ({}) | <char1> [walk] <sink> ({})'.format(microwave_id, sink_id),\n",
    "    '<char0> [putin] <salmon> ({}) <microwave> ({}) | <char1> [putback] <glass> ({}) <sink> ({})'.format(salmon_id, microwave_id, glass_id, sink_id),\n",
    "    '<char0> [close] <microwave> ({}) | <char1> [switchon] <faucet> ({})'.format(microwave_id, faucet_id)\n",
    "]\n",
    "comm.render_script(script, frame_rate=10, camera_mode=[\"PERSON_FROM_BACK\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive agents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have seen how to generate videos, but we can use the same command to deploy or train agents in the environment. You can execute the previous instructions one by one, and get an observation or graph at every step. or that, you don't need to generate videos or have animations, since it will slow down your agents. Use `skip_animation=True` to generate actions without animating them. Remember to turn off the recording mode as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the scene\n",
    "comm.reset(0)\n",
    "\n",
    "# Add two agents this time\n",
    "comm.add_character('Chars/Male2', initial_room='kitchen')\n",
    "comm.add_character('Chars/Female4', initial_room='bedroom')\n",
    "\n",
    "# Get nodes for salmon and microwave, glass, faucet and sink\n",
    "salmon_id = [node['id'] for node in g['nodes'] if node['class_name'] == 'salmon'][0]\n",
    "microwave_id = [node['id'] for node in g['nodes'] if node['class_name'] == 'microwave'][0]\n",
    "glass_id = [node['id'] for node in g['nodes'] if node['class_name'] == 'waterglass'][-1]\n",
    "sink_id = [node['id'] for node in g['nodes'] if node['class_name'] == 'sink'][0]\n",
    "faucet_id = [node['id'] for node in g['nodes'] if node['class_name'] == 'faucet'][-1]\n",
    "\n",
    "\n",
    "# Put salmon in microwave\n",
    "script = [\n",
    "    '<char0> [walk] <salmon> ({}) | <char1> [walk] <glass> ({})'.format(salmon_id, glass_id),\n",
    "    '<char0> [grab] <salmon> ({}) | <char1> [grab] <glass> ({})'.format(salmon_id, glass_id),\n",
    "    '<char0> [open] <microwave> ({}) | <char1> [walk] <sink> ({})'.format(microwave_id, sink_id),\n",
    "    '<char0> [putin] <salmon> ({}) <microwave> ({}) | <char1> [putback] <glass> ({}) <sink> ({})'.format(salmon_id, microwave_id, glass_id, sink_id),\n",
    "    '<char0> [close] <microwave> ({}) | <char1> [switchon] <faucet> ({})'.format(microwave_id, faucet_id)\n",
    "]\n",
    "\n",
    "s, cc = comm.camera_count()\n",
    "for script_instruction in script:\n",
    "    print(script_instruction)\n",
    "    comm.render_script([script_instruction], recording=False, skip_animation=True)\n",
    "    # Here you can get an observation, for instance\n",
    "    s, im = comm.camera_image([cc-3], image_width=300, image_height=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Physics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VirtualHome is also able to simulate physics in the environments, and you can use the following api call to alter the gravitational force experienced in the environemnt. By activating physics, all objects behave as expected, just like in the real world. However you can also alter the \"g-force\" to make the agent feel like they are a astronaut in space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the scene and get the graph\n",
    "comm.reset(3)\n",
    "s, g = comm.environment_graph()\n",
    "\n",
    "# Add a agent \n",
    "comm.add_character('Chars/female2', initial_room='kitchen')\n",
    "\n",
    "# Get nodes for pear and peach and bowl\n",
    "peach = [node['id'] for node in g['nodes'] if node['class_name'] == 'peach'][0]\n",
    "pear = [node['id'] for node in g['nodes'] if node['class_name'] == 'pear'][0]\n",
    "dishbowl = [node['id'] for node in g['nodes'] if node['class_name'] == 'dishbowl'][0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activate gravity\n",
    "comm.activate_physics()\n",
    "\n",
    "# Put peach and the pear in the bowl\n",
    "script = [\n",
    "          '<char0> [grab] <peach> ({})'.format(peach),\n",
    "          '<char0> [grab] <pear> ({})'.format(pear),\n",
    "          '<char0> [putin] <pear> ({}) <dishbowl> ({})'.format(pear, dishbowl),\n",
    "          '<char0> [putin] <peach> ({}) <dishbowl> ({})'.format(peach, dishbowl)\n",
    "         ]\n",
    "\n",
    "success, message = comm.render_script(script=script, \n",
    "                                      find_solution=False,\n",
    "                                      processing_time_limit=80,\n",
    "                                      frame_rate=15,\n",
    "                                      image_width=512, image_height=320,\n",
    "                                      skip_animation=False,\n",
    "                                      image_synthesis=['normal'],\n",
    "                                      camera_mode=['PERSON_TOP'],\n",
    "                                      recording=True,\n",
    "                                      file_name_prefix='gravity')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
